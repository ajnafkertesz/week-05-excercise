---
title: "Week 5 Excercise"
author: "Ajna Kertesz"
date: "2/26/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Challange 1

```{r challange1, echo=FALSE}

library(dplyr)
library(tidyverse)
library(ggplot2)
library(mosaic)

f <- "https://raw.githubusercontent.com/difiore/ada-2022-datasets/main/IMDB-movies.csv"
d <- read_csv(f, col_names = TRUE)
#d %<>% filter(d, startYear %in% 1920:1979, runtimeMinutes %in% 60:180)

d <- filter(d, startYear %in% 1920:1979)
d <- filter(d, runtimeMinutes %in% 60:180)


d <- d %>% mutate(decade=
           case_when(
            startYear %in% 1920:1930 ~ "20s",
            startYear %in% 1931:1940 ~ "30s",
            startYear %in% 1941:1950 ~ "40s",
            startYear %in% 1951:1960 ~ "50s",
            startYear %in% 1961:1970 ~ "60s",
            startYear %in% 1971:1979 ~ "70s"))

head(d) 

#distribution of runtimeMovies per decade

p<-ggplot(data = d, aes(x = runtimeMinutes)) + geom_histogram()

p<- p+ facet_wrap(~decade)

p

#Use a one-line statement to calculate the population mean and population standard deviation in runtimeMinutes for each decade and save the results in a new dataframe called results.

d%>%
  group_by(decade) %>%
  summarize(mean=mean(runtimeMinutes), sd=sd(runtimeMinutes))->results

results

#Draw a single sample of 100 movies, without replacement, from each decade and calculate the single sample mean and single sample standard deviation in runtimeMinutes for each decades. Recall that your single sample mean for each decade is an estimate of the population mean for each decade.

#select a sample from each decade


d%>%
  select(runtimeMinutes, decade)%>%
  group_by(decade) %>%
  sample_n(100, replace=FALSE) %>%
  summarise_each(funs(mean, sd)) ->sampleresults


sampleresults

#calculate mean and sd for each sample

sampleresults<-sampleresults%>%
  mutate(standard_error=(sd/sqrt(100)))

#Compare these estimates to the actual population mean runtimeMinutes for each decade and to the calculated SE in the population mean for samples of size 100 based on the population standard deviation for each decade.


head(sampleresults)
head(results) #when comparing we can see that they are almost exactly the same with only a less than +,-2 change in mean

#Generate a sampling distribution of mean runtimeMinutes for each decade by [a] drawing 1000 samples of 100 movies from each decade and, for each sample, [b] calculating the mean runtimeMinutes and the standard deviation in runtimeMinutes for each decade. Use either the do(reps) * formulation from {mosaic}, the rerun() function from {purrr}, or the rep_sample_n() workflow from {infer} to generate your these sampling distributions.


reps<-1000

samp_dist_mean <- 
  {do(reps) * sample_n(d,100, replace=FALSE)}%>%
  group_by(decade,.index)%>%
  summarize(mean=mean(runtimeMinutes), sd=sd(runtimeMinutes))

samp_dist_mean


#Then, calculate the MEAN and the STANDARD DEVIATION of the sampling distribution of sample means for each decade (the former should be a very good estimate of the population mean, while the latter is another estimate of the standard error in our estimate of the population mean for a particular sample size) and plot a histogram of the sampling distribution for each decade. What shape does it have?
reps<-100

samp_dist_mean<-
  {do(reps) * sample_n(samp_dist_mean,100, replace=FALSE)}%>%
mutate(MEAN=mean(mean), STANDARD_DEVIATION=sd(sd, na.rm=TRUE))

samp_dist_mean

p1<-ggplot(data = samp_dist_mean, aes(x = "Mean of runtimeMinutes")) + geom_histogram()

p1<- p+ facet_wrap(~decade)

#Finally, compare the standard error in runtimeMinutes for samples of size 100 from each decade [1] as estimated from your first sample of 100 movies, [2] as calculated from the known population standard deviations for each decade, and [3] as estimated from the sampling distribution of sample means for each decade.

#[1]compare to the estimate from the 100 movies sample
mean(sampleresults$sd) #19.97581

#[2]known population sd for each decade
mean(results$sd, na.rm=TRUE) #20.02343


#[3]sampling distribution of sample means for each decade
mean(samp_dist_mean$sd, na.rm=TRUE) #19.08625



```

## Challange 2


```{r challange2, echo=FALSE}

library(radiant)

zombies<- "https://raw.githubusercontent.com/difiore/ada-2022-datasets/main/zombies.csv"
z<- read_csv(zombies, col_names = TRUE)

 z%>%
   mutate(heightm=mean(height),heightsd=sdpop(height))%>%
    mutate(weightm=mean(weight),weightsd=sdpop(weight))%>%
    mutate(agem=mean(age), agesd=sdpop(age))%>%
    mutate(zombies_killedm=mean(zombies_killed), zkilledsd=sdpop(zombies_killed))%>%
    mutate(educationm=mean(years_of_education), educationsd=sdpop(years_of_education))


#Use {ggplot} and make boxplots of each of these variables by gender.

boxplot(height ~ gender, data=z, xlab="", ylab="Height")
ggplot(z, aes(x=height, y=gender)) + 
  geom_boxplot()

ggplot(z, aes(x=weight, y=gender)) + 
  geom_boxplot()

boxplot(weight ~ gender, data=z, xlab="", ylab="Weight")


ggplot(z, aes(x=age, y=gender)) + 
  geom_boxplot()
boxplot(age ~ gender, data=z, xlab="", ylab="Age")


ggplot(z, aes(x=zombies_killed, y=gender)) + 
  geom_boxplot()
boxplot(zombies_killed ~ gender, data=z, xlab="", ylab="Zombies killed")

ggplot(z, aes(x=years_of_education, y=gender)) + 
  geom_boxplot()
boxplot(years_of_education ~ gender, data=z, xlab="", ylab="Years of education")

 
#Use {ggplot} and make scatterplots of height and weight in relation to age (i.e., use age as the x variable), using different colored points for males versus females. Do these variables seem to be related? In what way?

height_scatter<-ggplot(z, aes(x=age, y=height, color=gender)) + geom_point()
height_scatter

weight_scatter<-ggplot(z, aes(x=age, y=weight, color=gender)) + geom_point()
weight_scatter

##at any given age, male zombies generally have higher weight and height and most zombies regardless of age seem to grow until they are 30 years old.

#Using histograms and Q-Q plots, check whether each of the quantitative variables seem to be drawn from a normal distribution. Which seem to be and which do not?

library(mosaic)

histogram(~ height, data=z, xlab="Average Height")
qqnorm(z$height)

histogram(~ weight, data=z, xlab="Average Weight")
qqnorm(z$weight)

histogram(~ age, data=z, xlab="Average Age")
qqnorm(z$age)

histogram(~ zombies_killed, data=z, xlab="Average Number of Zombies Killed")
qqnorm(z$zombies_killed)

histogram(~ years_of_education, data=z, xlab="Average Number of Years of Education")
qqnorm(z$years_of_education)

#Now use the sample_n() function from {dplyr} to sample ONE subset of 50 zombie apocalypse survivors (without replacement) from this population and calculate the mean and sample standard deviation for each variable. Also estimate the standard error for each variable based on this one sample and use that to construct the theoretical 95% confidence interval for each mean. You can use either the standard normal or a Studentâ€™s t distribution to derive the critical values needed to calculate the lower and upper limits of the CI.

z%>%
  select(height, weight, age, zombies_killed, years_of_education)%>%
  sample_n(50, replace=FALSE)%>%
  summarize(weightm=mean(weight), weightsd=sd(weight),
  heightm=mean(height), heightsd=sd(height),
  agem=mean(age), agesd=sd(age),
  educationm=mean(years_of_education), educationsd=sd(years_of_education),
  killedm=mean(zombies_killed), killedsd=sd(zombies_killed)) ->z_sample

z_sample


alpha<-.05

#weight
(se_weight <- z_sample$weightsd/sqrt(50))
(ci_weight <- z_sample$weightm + c(-1, 1) * qnorm(1 - alpha / 2) * se_weight) 

#height
(se_height <- z_sample$heightsd/sqrt(50))
(ci_height <- z_sample$heightm + c(-1, 1) * qnorm(1 - alpha / 2) * se_height) 

#age
(se_age <- z_sample$agesd/sqrt(50))
(ci_age <- z_sample$agem + c(-1, 1) * qnorm(1 - alpha / 2) * se_age) 

#education
(se_education <- z_sample$educationsd/sqrt(50))
(ci_education <- z_sample$educationm + c(-1, 1) * qnorm(1 - alpha / 2) * se_education) 

#zombies killed
(se_killed <- z_sample$killedsd/sqrt(50))
(ci_killed <- z_sample$killedm + c(-1, 1) * qnorm(1 - alpha / 2) * se_killed) 



#Then draw another 199 random samples of 50 zombie apocalypse survivors out and calculate the mean for each of the these samples. Together with the first sample you drew out, you now have a set of 200 means for each variable (each based on 50 observations), which constitutes a sampling distribution for each variable. What are the means and standard deviations of the sampling distribution for each variable?

reps<-199

z_samples<-
  {do(reps) * sample_n(z,50, replace=FALSE)}%>%
  group_by(.index)%>%
  summarize(weightm=mean(weight), weightsd=sd(weight),
  heightm=mean(height), heightsd=sd(height),
  agem=mean(age), agesd=sd(age),
  educationm=mean(years_of_education), educationsd=sd(years_of_education),
  killedm=mean(zombies_killed), killedsd=sd(zombies_killed)) 


#create .index column in z_sample
z_sample%>%
  mutate(.index=0)->z_sample

#merge single sample and 199 sample
total <- rbind(z_sample,z_samples)

total

total%>%
  summarize(weightm=mean(weightm), weightsd=sd(weightsd),
  heightm=mean(heightm), heightsd=sd(heightsd),
  agem=mean(agem), agesd=sd(agesd),
  educationm=mean(educationm), educationsd=sd(educationsd),
  killedm=mean(killedm), killedsd=sd(killedsd)) ->sample_dist
  
sample_dist

#Finally, construct a 95% confidence interval for each mean directly from the sampling distribution of sample means using the central 95% that distribution (i.e., by setting the lower and upper CI bounds to 2.5% and 97.5% of the way through that distribution).

#200 means--> create a dist with the quantile function

#weight
quantile(total$weightm, 0.025) #139.1517
quantile(total$weightm, 0.975) #147.8754

#height
quantile(total$heightm, 0.025) #66.4955
quantile(total$heightm, 0.975) #147.8754

#age
quantile(total$agem, 0.025) #19.24803
quantile(total$agem, 0.975) #20.86467

#education
quantile(total$educationm, 0.025) #2.56
quantile(total$educationm, 0.975) #3.4205

#zombies killed
quantile(total$killedm, 0.025) #2.5995
quantile(total$killedm, 0.975) #3.52


#How do the standard deviations of the sampling distribution for each variable compare to the standard errors estimated from your first sample of size 50? What do sampling distributions for each variable mean look like? Are they normally distributed? What about for those variables that you concluded were not originally drawn from a normal distribution? How do the two 95% CIs you estimated compare to one another (i.e., the CI based on one sample and the corresponding sample standard deviation versus the CI based on simulation where you created a sampling distribution across 200 samples)?


#table with sd of sampling dist and the sampling dist estimate sample sd/sqrt sample size

#single sample estimates
z_sample%>% 
  select(weightsd, heightsd, agesd, educationsd, killedsd)%>%
  summarize(weightse=(weightsd/sqrt(1)), heightse=(heightsd/sqrt(1)), agese=(agesd/sqrt(1)), educationse=(educationsd/sqrt(1)), killedseweightse=(killedsd/sqrt(1)))

#200 sample estimates
z_samples%>% 
  select(weightsd, heightsd, agesd, educationsd, killedsd)%>%
  summarize(weightse=(weightsd/sqrt(200)), heightse=(heightsd/sqrt(200)), agese=(agesd/sqrt(200)), educationse=(educationsd/sqrt(200)), killedseweightse=(killedsd/sqrt(200)))



```

